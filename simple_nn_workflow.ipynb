{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datasets.token_price import TokenDataset\n",
    "from models.simple_nn import SimpleNN\n",
    "from models.linear_regression import LinearRegression\n",
    "from models.utils import convert_to_onnx\n",
    "from training.evaluation import k_fold_cross_validation\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "import proof.ezkl as ezkl\n",
    "from utils import green\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from skl2onnx import to_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LAG = 1 \n",
    "TOKEN_NAME = \"WETH\" # Choose one of the available tokens in the main dataset.\n",
    "STARTER_DATE = pl.datetime(2022, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset read from cache.\n",
      "Loading dataset tokens-daily-prices-mcap-volume from cache.\n",
      "Dataset read from cache.\n",
      "Loading dataset top-pools-apy-per-protocol from cache.\n",
      "Dataset read from cache.\n",
      "Loading dataset tvl-per-project-tokens from cache.\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets.\n",
    "x_train, x_test, y_train, y_test = TokenDataset.get_train_test_split(TOKEN_NAME, STARTER_DATE, TARGET_LAG, split_ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the training set:\n",
      "shape: (5, 120)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ tvlUsd_pr â”† apy_proje â”† apy_proje â”† apy_proje â”† â€¦ â”† pendle   â”† diff_pric â”† rocket-po â”† tvlUsd_pr â”‚\n",
      "â”‚ oject_sus â”† ct_uniswa â”† ct_sushis â”† ct_uniswa â”†   â”† ---      â”† e_1_days_ â”† ol        â”† oject_sus â”‚\n",
      "â”‚ hiswap_Et â”† p-v3_Arbi â”† wap_Ether â”† p-v2_Ethe â”†   â”† f64      â”† agoWETH   â”† ---       â”† hiswap_Et â”‚\n",
      "â”‚ hereuâ€¦    â”† trumWâ€¦    â”† eumWEâ€¦    â”† reumXâ€¦    â”†   â”†          â”† ---       â”† f64       â”† hereuâ€¦    â”‚\n",
      "â”‚ ---       â”† ---       â”† ---       â”† ---       â”†   â”†          â”† f64       â”†           â”† ---       â”‚\n",
      "â”‚ f64       â”† f64       â”† f64       â”† f64       â”†   â”†          â”†           â”†           â”† f64       â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 1.787736  â”† -0.520166 â”† -0.125548 â”† -0.319669 â”† â€¦ â”† 0.162243 â”† -2.144109 â”† -0.853152 â”† 4.647859  â”‚\n",
      "â”‚ 1.607506  â”† -0.549403 â”† -0.186733 â”† 0.075711  â”† â€¦ â”† 0.163407 â”† 0.090246  â”† -0.845938 â”† 4.356967  â”‚\n",
      "â”‚ 0.0       â”† 0.0       â”† 0.0       â”† 0.0       â”† â€¦ â”† 0.158077 â”† -1.003463 â”† -0.867701 â”† 0.0       â”‚\n",
      "â”‚ 1.367605  â”† -0.850676 â”† -0.386693 â”† -0.319669 â”† â€¦ â”† 0.161605 â”† 0.538089  â”† -0.85498  â”† 4.475475  â”‚\n",
      "â”‚ 1.465036  â”† -0.60348  â”† -0.265911 â”† -0.319669 â”† â€¦ â”† 0.161219 â”† 0.041101  â”† -0.846836 â”† 4.646354  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Get some information about the dataset.\n",
    "print(\"First 5 rows of the training set:\")\n",
    "print(x_train.head(5))\n",
    "\n",
    "x_test[int(len(x_test) * 0.6):].write_csv(\"./example_token_trend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to PyTorch tensors.\n",
    "x_train, x_test, y_train, y_test = tuple(\n",
    "    map(lambda x: torch.tensor(x.to_numpy(), dtype=torch.float32), [x_train, x_test, y_train, y_test])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_train.shape[1]\n",
    "\n",
    "PYTORCH_MODELS = {\n",
    "    \"Neural Network\": k_fold_cross_validation(x_train, y_train, SimpleNN(input_size), nn.BCELoss(), optim.Adam),\n",
    "    \"Linear Regression\": k_fold_cross_validation(x_train, y_train, LinearRegression(input_size), nn.MSELoss(), optim.Adam)\n",
    "}\n",
    "\n",
    "y_train_as_1d_array = y_train.squeeze().numpy()\n",
    "y_test_as_1d_array = y_test.squeeze().numpy()\n",
    "\n",
    "SKLEARN_MODELS = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(criterion=\"log_loss\", max_depth=5),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=100),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "SKLEARN_MODELS = {\n",
    "    model_name: model.fit(x_train, y_train_as_1d_array) \n",
    "    for model_name, model in SKLEARN_MODELS.items()\n",
    "}\n",
    "\n",
    "SKLEARN_MODELS = {\n",
    "    model_name: (model, model.score(x_test, y_test_as_1d_array)) \n",
    "    for model_name, model in SKLEARN_MODELS.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy: \u001b[92m0.52\u001b[0m\n",
      "Logistic Regression - Accuracy: \u001b[92m0.58\u001b[0m\n",
      "Random Forest - Accuracy: \u001b[92m0.53\u001b[0m\n",
      "SVM - Accuracy: \u001b[92m0.59\u001b[0m\n",
      "Neural Network - Accuracy: \u001b[92m0.66\u001b[0m\n",
      "Linear Regression - Accuracy: \u001b[92m0.74\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Print the results of the models.\n",
    "for model_name, (model, score) in (SKLEARN_MODELS | PYTORCH_MODELS).items():\n",
    "    print(f\"{model_name} - Accuracy: {green(str(score)[:4])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as ONNX\n",
    "ONNX_PATH = \"onnx/\"\n",
    "path = lambda model_name: ONNX_PATH + model_name.replace(\" \", \"_\").lower() + \".onnx\"\n",
    "shape = x_test.shape[1:]\n",
    "sample = torch.rand(1, *shape, requires_grad=True)\n",
    "\n",
    "for model_name, (model, _) in PYTORCH_MODELS.items():\n",
    "    convert_to_onnx(model, sample, path(model_name))\n",
    "\n",
    "for model_name, (model, _) in SKLEARN_MODELS.items():\n",
    "    onx = to_onnx(model, sample.detach().numpy())\n",
    "    with open(path(model_name), \"wb\") as f:\n",
    "        f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EZKL Proof  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree proof:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to generate settings: Translating node #3 \"ZipMap\" Unimplemented(ZipMap) ToTypedTranslator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, (model, _) \u001b[38;5;129;01min\u001b[39;00m (SKLEARN_MODELS)\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m proof:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mbench\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(model, model_name)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bench \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m model, model_name: \u001b[43mezkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbench_ezkl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, (model, _) \u001b[38;5;129;01min\u001b[39;00m (SKLEARN_MODELS)\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m proof:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/model-poc/proof/ezkl.py:119\u001b[0m, in \u001b[0;36mbench_ezkl\u001b[0;34m(model, model_onnx_file, sample, shape, rounds)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rounds):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mredirect_stderr(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 119\u001b[0m         s, p, v \u001b[38;5;241m=\u001b[39m \u001b[43mbench_ezkl_single_round\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_onnx_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     setup_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m s\n\u001b[1;32m    121\u001b[0m     prove_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p\n",
      "File \u001b[0;32m~/model-poc/proof/ezkl.py:100\u001b[0m, in \u001b[0;36mbench_ezkl_single_round\u001b[0;34m(model, model_onnx_file, sample, shape)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbench_ezkl_single_round\u001b[39m(model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, sk\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mBaseEstimator], model_onnx_file: \u001b[38;5;28mstr\u001b[39m, sample: torch\u001b[38;5;241m.\u001b[39mTensor, shape: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m     99\u001b[0m     setup_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 100\u001b[0m     \u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_onnx_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     setup_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    103\u001b[0m     prove_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/model-poc/proof/ezkl.py:72\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(model, model_onnx_file, sample, shape)\u001b[0m\n\u001b[1;32m     70\u001b[0m create_files()\n\u001b[1;32m     71\u001b[0m save_input(model, sample, shape)\n\u001b[0;32m---> 72\u001b[0m \u001b[43mgen_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_onnx_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m gen_calibration(shape, model_onnx_file)\n\u001b[1;32m     74\u001b[0m compile_model(model_onnx_file)\n",
      "File \u001b[0;32m~/model-poc/proof/ezkl.py:48\u001b[0m, in \u001b[0;36mgen_settings\u001b[0;34m(model_onnx_file)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen_settings\u001b[39m(model_onnx_file: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mezkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_settings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_onnx_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mSETTINGS\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to generate settings: Translating node #3 \"ZipMap\" Unimplemented(ZipMap) ToTypedTranslator"
     ]
    }
   ],
   "source": [
    "bench = lambda model, model_name: ezkl.bench_ezkl(model, path(model_name), sample, shape, 1)\n",
    "\n",
    "for model_name, (model, _) in (PYTORCH_MODELS | SKLEARN_MODELS).items():\n",
    "    print(f\"{model_name} proof:\")\n",
    "    bench(model, model_name)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezkl.setup(\n",
    "    model1, \n",
    "    MODEL_ONNX,\n",
    "    sample, \n",
    "    shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ezkl.prove()\n",
    "end = time.time()\n",
    "print(f\"Proving time: {green(str(end - start)[:5] + ' [s]')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ezkl.verify()\n",
    "end = time.time()\n",
    "print(f\"Verification time: {green(str(end - start)[:5] + ' [s]')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giza Proof "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpile the models to cairo using Giza\n",
    "! giza transpile onnx/model1.onnx --output-path model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the endpoint to Giza\n",
    "! giza endpoints deploy --model-id 584 --version-id 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! giza workspaces get\n",
    "\n",
    "# ðŸš¨ If you haven't set up a workspace yet, you can establish one by executing the command below:\n",
    "# `! giza workspaces create`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giza_actions.action import action\n",
    "from giza_actions.model import GizaModel\n",
    "from giza_actions.task import task\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@task(name=\"Prediction with Cairo\")\n",
    "def prediction(X_test, model):\n",
    "    (result, request_id) = model.predict(\n",
    "        input_feed={\"input\": X_test},\n",
    "        verifiable=True,\n",
    "        custom_output_dtype=\"arr_fixed_point\",\n",
    "    )\n",
    "    return result, request_id\n",
    "\n",
    "\n",
    "@action(name=\"Execution: Prediction with Cairo\", log_prints=True)\n",
    "def execution():\n",
    "    model = GizaModel(id=584, version=3)\n",
    "    df = pl.read_csv(\"./example_token_trend.csv\")\n",
    "    model_input = df.to_numpy().astype(np.float32)\n",
    "    (result, request_id) = prediction(model_input, model)\n",
    "    return result, request_id\n",
    "\n",
    "\n",
    "(result, request_id) = execution()\n",
    "print(f\"Result: {result}, Request ID: {request_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
