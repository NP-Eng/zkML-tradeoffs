{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EZKL Workflow\n",
    "\n",
    "To prove the inference of a trained model using EZKL, we need to follow the steps below. As an example to illustrate the process, let's consider that we have just trained a simple perceptron model using PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "# MNIST dataset\n",
    "train, test = (torchvision.datasets.MNIST(\n",
    "    './data', \n",
    "    train=is_train,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        torchvision.transforms.Lambda(lambda x: x.view(-1))\n",
    "    ])\n",
    ") for is_train in [True, False])\n",
    "\n",
    "input_size, output_size = 28 * 28, 10\n",
    "\n",
    "# Define the model\n",
    "perceptron = nn.Sequential(\n",
    "    nn.Linear(input_size, output_size),\n",
    ")\n",
    "\n",
    "# Create a dataset and data loader\n",
    "train_loader, test_loader = (DataLoader(\n",
    "    dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ") for dataset in [train, test])\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(perceptron.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "perceptron.train()\n",
    "for data, label in train_loader:\n",
    "    output = perceptron(data)\n",
    "    loss = criterion(output, label)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.63%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "perceptron.eval()\n",
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    for data, label in test_loader:\n",
    "        output = perceptron(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Model Conversion**\n",
    "\n",
    "Convert the trained model to the ONNX format. In this case, PyTorch provides the function torch.onnx.export. Other frameworks also have similar functions or external tools to convert models to ONNX (e.g., TensorFlow's tf2onnx). Nevertheless, Sklearn models are slighly more complicated to convert to suitable ONNX format, so we must first convert the model to a PyTorch using hummingbird.ml and then convert it to ONNX. We won't cover this process in this article but you can find more information in one of EZKL's notebooks.\n",
    "\n",
    "Before converting our model to ONNX format, we need to tell the converter the input shape of the model. This can be done by passing a dummy input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose any valid input tensor (1st input of the test dataset)\n",
    "input_sample = next(iter(test_loader))[0][0].unsqueeze(0)\n",
    "\n",
    "torch.onnx.export(\n",
    "    perceptron,\n",
    "    input_sample,\n",
    "    \"perceptron.onnx\",\n",
    "    opset_version=10,\n",
    "    export_params=True,                # Store the trained parameter weights inside the model file\n",
    "    do_constant_folding=True,          # Optimize constant values in the model graph\n",
    "    input_names = ['input'],             # Input and output labels to appear in the ONNX graph \n",
    "    output_names = ['output'],\n",
    "    dynamic_axes={\n",
    "        'input' : {0 : 'batch_size'},    # Variable length axes\n",
    "        'output' : {0 : 'batch_size'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Setup**\n",
    "\n",
    "EZKL has several setup functions in their exposed API, namely gen_settings, calibrate_settings, compile_circuit, get_srs, setup, and gen_witness, we've group them together in this bullet point to describe the high level setup process. The signature of each function should be self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 5 columns for non-linearity table.\n",
      "Using 10 columns for non-linearity table.\n",
      "calibration failed extended k is too large to accommodate the quotient polynomial with logrows 6\n",
      "Using 10 columns for non-linearity table.\n",
      "calibration failed extended k is too large to accommodate the quotient polynomial with logrows 6\n",
      "calibration failed max lookup input (-443955313, 187951024) is too large\n",
      "calibration failed max lookup input (-444003028, 187964918) is too large\n",
      "calibration failed max lookup input (-888003166, 375923425) is too large\n",
      "calibration failed max lookup input (-1775805070, 751629926) is too large\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+---------------+----------------+--------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error    | median_error   | max_error    | min_error      | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+---------------+----------------+--------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0.00053642393 | -0.00008678436 | 0.0015144348 | -0.00012040138 | 0.0005938828   | 0.00008678436    | 0.0015144348  | 0.00008010864 | 0.0000006270852    | -0.00011826501     | 0.00017385074          |\n",
      "+---------------+----------------+--------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ezkl\n",
    "import json\n",
    "\n",
    "def create_file(filename: str) -> str:\n",
    "    # If the file already exists, clear it\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    open(filename, 'w').close()\n",
    "    return filename\n",
    "\n",
    "# We have to create empty files manually before running the setup\n",
    "INPUT = create_file(\"input_data.json\")\n",
    "SETTINGS = create_file(\"settings.json\")\n",
    "CALIBRATION = create_file(\"calibration.json\")\n",
    "WITNESS = create_file(\"witness.json\")\n",
    "COMPILED_MODEL = create_file(\"model.compiled\")\n",
    "VK = create_file(\"vk.json\")\n",
    "PK = create_file(\"pk.json\")\n",
    "PROOF = create_file(\"proof.json\")\n",
    "\n",
    "def setup(onnx_file: str, model: nn.Module, input_sample: torch.Tensor):\n",
    "\n",
    "    # Create empty files for each of the required inputs\n",
    "    for filename in [INPUT, SETTINGS, CALIBRATION, WITNESS, COMPILED_MODEL, VK, PK, PROOF]:\n",
    "        create_file(filename)\n",
    "\n",
    "    # Save the input data to a file in the expected format\n",
    "    input_data = {\n",
    "        'input_shapes': list(input_sample.shape),\n",
    "        'input_data': input_sample.detach().numpy().tolist(),\n",
    "        \"output_data\": model(input_sample).detach().numpy().tolist()\n",
    "    }\n",
    "\n",
    "    json.dump(\n",
    "        input_data,\n",
    "        open(INPUT, 'w')\n",
    "    )\n",
    "\n",
    "    # Run each setup function and verify that it succeeded\n",
    "    assert ezkl.gen_settings(\n",
    "        onnx_file,\n",
    "        SETTINGS\n",
    "    )\n",
    "\n",
    "    calibration_data = {\n",
    "        'input_data': torch.randn(20, input_sample.shape[1]).numpy().tolist()\n",
    "    }\n",
    "\n",
    "    json.dump(\n",
    "        calibration_data,\n",
    "        open(CALIBRATION, 'w')\n",
    "    )\n",
    "\n",
    "    assert ezkl.calibrate_settings(\n",
    "        INPUT,\n",
    "        onnx_file,\n",
    "        SETTINGS, \n",
    "        \"resources\"\n",
    "    )\n",
    "\n",
    "    assert ezkl.compile_circuit(\n",
    "        onnx_file,\n",
    "        COMPILED_MODEL,\n",
    "        SETTINGS\n",
    "    )\n",
    "\n",
    "    assert ezkl.get_srs(\n",
    "        SETTINGS\n",
    "    )\n",
    "\n",
    "    ezkl.gen_witness(\n",
    "        \"input_data.json\",\n",
    "        COMPILED_MODEL,\n",
    "        WITNESS\n",
    "    )\n",
    "\n",
    "    assert ezkl.setup(\n",
    "        COMPILED_MODEL,\n",
    "        VK,\n",
    "        PK\n",
    "    )\n",
    "\n",
    "setup(\"perceptron.onnx\", perceptron, input_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Proof Generation**: Generate the proof using the `gen_proof` function. This function takes the arithmetization of the model, the witness, the public key, and the proof file as inputs and writes the proof to the specified file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instances': [['c6afe78593f5e1439170b97948e833285d588181b64550b829a031e1724e6430',\n",
      "                'b3a071ac93f5e1439170b97948e833285d588181b64550b829a031e1724e6430',\n",
      "                'fd233cec93f5e1439170b97948e833285d588181b64550b829a031e1724e6430',\n",
      "                'e61a3c0c00000000000000000000000000000000000000000000000000000000',\n",
      "                '36d94ed493f5e1439170b97948e833285d588181b64550b829a031e1724e6430',\n",
      "                'a990262d00000000000000000000000000000000000000000000000000000000',\n",
      "                'ed56c4df93f5e1439170b97948e833285d588181b64550b829a031e1724e6430',\n",
      "                'f2f932e093f5e1439170b97948e833285d588181b64550b829a031e1724e6430',\n",
      "                '24bea62c00000000000000000000000000000000000000000000000000000000',\n",
      "                '4e394f2200000000000000000000000000000000000000000000000000000000']],\n",
      " 'proof': '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',\n",
      " 'transcript_type': 'EVM'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "proof = ezkl.prove(\n",
    "    WITNESS,\n",
    "    COMPILED_MODEL,\n",
    "    PK,\n",
    "    PROOF,\n",
    "    \"single\",\n",
    ")\n",
    "\n",
    "pprint.pprint(proof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Proof Verification**: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ezkl.verify(\n",
    "    PROOF,\n",
    "    SETTINGS,\n",
    "    VK\n",
    ") == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Trend Forecasting\n",
    "\n",
    "We adapted code from one of [GIZA's examples](https://github.com/gizatechxyz/Giza-Hub/tree/token_trend_action/awesome-giza-actions/trend_token_prediction) the idea is to train multiple models with different accuracies and then compare the costs of proving the inference of each model. We first \n",
    "explain the feature extraction process in detail, which is not explained in the original example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We will use the [Giza's dataset hub](https://github.com/gizatechxyz/datasets), which contains a collection of datasets that are relevant for blockchain applications. These datasets are publicly available and can be loaded using the `DatasetsLoader` class from the `giza_datasets` package, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset read from cache.\n",
      "Loading dataset tokens-daily-prices-mcap-volume from cache.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from giza_datasets import DatasetsLoader\n",
    "import polars as pl\n",
    "\n",
    "# Load the desired dataset\n",
    "DatasetsLoader().load(\"tokens-daily-prices-mcap-volume\")\n",
    "\n",
    "# For pretty printing\n",
    "pl.Config.set_tbl_hide_column_data_types(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Token Daily Price Data\n",
    "Contains daily price data (price, market capitalization, and volume) for a set of tokens (e.g., WBTC, WETH, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "Dataset read from cache.\n",
      "Loading dataset tokens-daily-prices-mcap-volume from cache.\n",
      "shape: (3, 5)\n",
      "┌────────────┬─────────────┬────────────┬──────────────────┬───────┐\n",
      "│ date       ┆ price       ┆ market_cap ┆ volumes_last_24h ┆ token │\n",
      "╞════════════╪═════════════╪════════════╪══════════════════╪═══════╡\n",
      "│ 2019-02-01 ┆ 3438.360403 ┆ 0.0        ┆ 20589.040403     ┆ WBTC  │\n",
      "│ 2019-02-02 ┆ 3472.243307 ┆ 0.0        ┆ 12576.723906     ┆ WBTC  │\n",
      "│ 2019-02-03 ┆ 3461.058341 ┆ 0.0        ┆ 1852.526033      ┆ WBTC  │\n",
      "└────────────┴─────────────┴────────────┴──────────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows of the dataset:\")\n",
    "print(DatasetsLoader().load('tokens-daily-prices-mcap-volume').head(n = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top APY per protocol\n",
    "Contains the top Annual Percentage Yield (APY) for each protocol in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "Dataset read from cache.\n",
      "Loading dataset top-pools-apy-per-protocol from cache.\n",
      "shape: (3, 6)\n",
      "┌────────────┬──────────┬─────┬─────────┬──────────────────┬──────────┐\n",
      "│ date       ┆ tvlUsd   ┆ apy ┆ project ┆ underlying_token ┆ chain    │\n",
      "╞════════════╪══════════╪═════╪═════════╪══════════════════╪══════════╡\n",
      "│ 2022-02-28 ┆ 12808    ┆ 0.0 ┆ aave-v2 ┆ STETH            ┆ Ethereum │\n",
      "│ 2022-03-01 ┆ 46045250 ┆ 0.0 ┆ aave-v2 ┆ STETH            ┆ Ethereum │\n",
      "│ 2022-03-02 ┆ 90080754 ┆ 0.0 ┆ aave-v2 ┆ STETH            ┆ Ethereum │\n",
      "└────────────┴──────────┴─────┴─────────┴──────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows of the dataset:\")\n",
    "print(DatasetsLoader().load('top-pools-apy-per-protocol').head(n = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TVL per project tokens\n",
    "Contains the Total Value Locked (TVL) for each project in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "Dataset read from cache.\n",
      "Loading dataset tvl-per-project-tokens from cache.\n",
      "shape: (3, 47)\n",
      "┌───────┬──────┬────────┬──────┬───┬──────┬──────┬────────────┬─────────┐\n",
      "│ 1INCH ┆ AAVE ┆ AAVE.E ┆ AMPL ┆ … ┆ YFI  ┆ ZRX  ┆ date       ┆ project │\n",
      "╞═══════╪══════╪════════╪══════╪═══╪══════╪══════╪════════════╪═════════╡\n",
      "│ null  ┆ null ┆ null   ┆ null ┆ … ┆ null ┆ null ┆ 2020-11-29 ┆ aave-v2 │\n",
      "│ null  ┆ null ┆ null   ┆ null ┆ … ┆ null ┆ null ┆ 2020-11-30 ┆ aave-v2 │\n",
      "│ null  ┆ null ┆ null   ┆ null ┆ … ┆ null ┆ null ┆ 2020-12-01 ┆ aave-v2 │\n",
      "└───────┴──────┴────────┴──────┴───┴──────┴──────┴────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows of the dataset:\")\n",
    "print(DatasetsLoader().load('tvl-per-project-tokens').head(n = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset read from cache.\n",
      "Loading dataset tokens-daily-prices-mcap-volume from cache.\n",
      "First few rows of the dataset:\n",
      "shape: (3, 19)\n",
      "┌────────────┬─────────┬────────────┬──────────────────┬───┬───────────────┬─────┬───────┬──────┐\n",
      "│ date       ┆ price   ┆ market_cap ┆ volumes_last_24h ┆ … ┆ trend_30_days ┆ day ┆ month ┆ year │\n",
      "╞════════════╪═════════╪════════════╪══════════════════╪═══╪═══════════════╪═════╪═══════╪══════╡\n",
      "│ 2018-02-14 ┆ 839.535 ┆ 0.0        ┆ 54776.5          ┆ … ┆ null          ┆ 3   ┆ 2     ┆ 2018 │\n",
      "│ 2018-02-15 ┆ 947.358 ┆ 0.0        ┆ 111096.0         ┆ … ┆ null          ┆ 4   ┆ 2     ┆ 2018 │\n",
      "│ 2018-02-16 ┆ 886.961 ┆ 0.0        ┆ 57731.7          ┆ … ┆ null          ┆ 5   ┆ 2     ┆ 2018 │\n",
      "└────────────┴─────────┴────────────┴──────────────────┴───┴───────────────┴─────┴───────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "TOKEN = \"WETH\"\n",
    "LAG = 1\n",
    "DAYS = [1, 3, 7, 15, 30]\n",
    "START_DATE = pl.datetime(2022, 6, 1)\n",
    "\n",
    "token_data = DatasetsLoader().load('tokens-daily-prices-mcap-volume')\n",
    "\n",
    "# Filter the dataset to only include the target token\n",
    "# Add a column with the labels for the target token\n",
    "# Add columns with the price difference over the specified DAYS\n",
    "# Expand the date column into day_of_week, month_of_year, and year\n",
    "target_token_price_trend = token_data \\\n",
    "    .filter(pl.col(\"token\") == TOKEN) \\\n",
    "    .with_columns(\n",
    "        ((pl.col(\"price\").shift(-LAG) - pl.col(\"price\")) > 0).cast(pl.Int8).alias(\"label\")\n",
    "    ) \\\n",
    "    .with_columns(\n",
    "        pl.col(\"price\").diff(n = days).alias(f\"price_diff_{days}_days\")\n",
    "        for days in DAYS\n",
    "    ) \\\n",
    "    .with_columns(\n",
    "        (pl.col(\"price\") - pl.col(\"price\").shift(days) > 0).cast(pl.Int8).alias(f\"trend_{days}_days\")\n",
    "        for days in DAYS\n",
    "    ) \\\n",
    "    .with_columns([\n",
    "        pl.col(\"date\").dt.weekday().alias(\"day\"),\n",
    "        pl.col(\"date\").dt.month().alias(\"month\"),\n",
    "        pl.col(\"date\").dt.year().alias(\"year\")\n",
    "    ])\n",
    "\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(target_token_price_trend.head(n = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset read from cache.\n",
      "Loading dataset tokens-daily-prices-mcap-volume from cache.\n"
     ]
    }
   ],
   "source": [
    "token_data = DatasetsLoader().load('tokens-daily-prices-mcap-volume')\n",
    "correlations = {}\n",
    "\n",
    "# List all tokens in the dataset\n",
    "tokens = token_data.get_column(\"token\").unique().to_list()\n",
    "\n",
    "# Calculate the correlation between the target token and all other tokens\n",
    "for token_1, token_2 in itertools.permutations(tokens, r=2):\n",
    "    \n",
    "    # Filter the dataset and get the price and date columns\n",
    "    token_1_data = token_data.filter(pl.col(\"token\") == token_1) \\\n",
    "        .select([\"date\", \"price\"])\n",
    "    token_2_data = token_data.filter(pl.col(\"token\") == token_2) \\\n",
    "        .select([\"date\", \"price\"])\n",
    "    \n",
    "    # Join the datasets on the date column\n",
    "    joined_data = token_1_data.join(token_2_data, on=\"date\", suffix=\"_compare\")\n",
    "\n",
    "    # Nested dictionary to store the correlation between the two tokens\n",
    "    correlations[token_1] = correlations.get(token_1, {}) \n",
    "    correlations[token_1][token_2] = correlations[token_1] \\\n",
    "        .get(token_2, {\n",
    "            day: joined_data \\\n",
    "                    .with_columns(pl.col(\"price_compare\").shift(day)) \\\n",
    "                    .select(pl.corr(\"price\", \"price_compare\").alias(\"correlation\")) \\\n",
    "                    .get_column(\"correlation\")[0]\n",
    "            for day in DAYS\n",
    "        })\n",
    "\n",
    "\n",
    "#pprint.pprint(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "shape: (3, 69)\n",
      "┌────────────┬─────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ date       ┆ price   ┆ market_ca ┆ volumes_l ┆ … ┆ price_tre ┆ price_tre ┆ price_tre ┆ price_tre │\n",
      "│            ┆         ┆ p         ┆ ast_24h   ┆   ┆ nd_GNO_3  ┆ nd_GNO_7  ┆ nd_GNO_15 ┆ nd_GNO_30 │\n",
      "╞════════════╪═════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 2018-02-14 ┆ 839.535 ┆ 0.0       ┆ 54776.5   ┆ … ┆ 0         ┆ 1         ┆ 0         ┆ 0         │\n",
      "│ 2018-02-15 ┆ 947.358 ┆ 0.0       ┆ 111096.0  ┆ … ┆ 1         ┆ 1         ┆ 0         ┆ 0         │\n",
      "│ 2018-02-16 ┆ 886.961 ┆ 0.0       ┆ 57731.7   ┆ … ┆ 1         ┆ 1         ┆ 0         ┆ 0         │\n",
      "└────────────┴─────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "\n",
    "# Dataframe to store the final results\n",
    "price_dataset = target_token_price_trend\n",
    "\n",
    "# Retrive the relevant data from the nested dictionary\n",
    "target_token_correlations = correlations[TOKEN]\n",
    "\n",
    "# Get the top K correlated tokens for each lag\n",
    "top_k_correlated_tokens_by_lag = {\n",
    "    lag: sorted(target_token_correlations.items(), key=lambda x: x[1][lag], reverse=True)[:K]\n",
    "    for lag in DAYS\n",
    "}\n",
    "\n",
    "top_k_correlated_tokens_15_days = top_k_correlated_tokens_by_lag[15]\n",
    "\n",
    "for token, _ in top_k_correlated_tokens_15_days:\n",
    "\n",
    "    # Column names for the price differences\n",
    "    price_diff_columns = [f\"price_diff_{token}_{days}\" for days in DAYS]\n",
    "    price_trend_columns = [f\"price_trend_{token}_{days}\" for days in DAYS]\n",
    "\n",
    "    # Filter the dataset to only include the correlated token\n",
    "    token_prices = token_data.filter(pl.col(\"token\") == token)\n",
    "\n",
    "    # Add columns with the price differences for each day\n",
    "    token_prices = token_prices \\\n",
    "        .with_columns(\n",
    "            pl.col(\"price\").diff(n = days).alias(tag)\n",
    "            for days, tag in zip(DAYS, price_diff_columns)\n",
    "        ) \\\n",
    "        .with_columns([\n",
    "            (pl.col(\"price\") - pl.col(\"price\").shift(days) > 0).cast(pl.Int8).alias(tag)\n",
    "            for days, tag in zip(DAYS, price_trend_columns)\n",
    "        ]) \\\n",
    "        .select([\"date\"] + price_diff_columns + price_trend_columns)\n",
    "\n",
    "    # Join the dataset with the target token dataset\n",
    "    price_dataset = price_dataset.join(token_prices, on=\"date\", how=\"left\")\n",
    "\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(price_dataset.head(n = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset read from cache.\n",
      "Loading dataset top-pools-apy-per-protocol from cache.\n",
      "First few rows of the dataset:\n",
      "shape: (3, 91)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ date      ┆ tvlUsd_pr ┆ tvlUsd_pr ┆ tvlUsd_pr ┆ … ┆ apy_proje ┆ apy_proje ┆ apy_proje ┆ apy_proj │\n",
      "│           ┆ oject_aav ┆ oject_aav ┆ oject_aav ┆   ┆ ct_uniswa ┆ ct_uniswa ┆ ct_uniswa ┆ ect_year │\n",
      "│           ┆ e-v2_Ethe ┆ e-v2_Poly ┆ e-v2_Aval ┆   ┆ p-v3_Arbi ┆ p-v3_Arbi ┆ p-v3_Ethe ┆ n-financ │\n",
      "│           ┆ reumW…    ┆ gonWE…    ┆ anche…    ┆   ┆ trumW…    ┆ trumW…    ┆ reumW…    ┆ e_Ethere │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 2022-02-1 ┆ 246215633 ┆ 560180650 ┆ 719972444 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 1         ┆ 5         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2022-02-1 ┆ 246420416 ┆ 537846447 ┆ 672831429 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 2         ┆ 1         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2022-02-1 ┆ 249160040 ┆ 508550871 ┆ 669386509 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 3         ┆ 0         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n",
      "Number of rows in the dataset: 711\n"
     ]
    }
   ],
   "source": [
    "top_apy_per_protocol = DatasetsLoader().load(\"top-pools-apy-per-protocol\")\n",
    "\n",
    "# Filter the dataset to only include protocols with the target token\n",
    "\"\"\" unique_token_projects = top_apy_per_protocol \\\n",
    "    .filter(pl.col(\"underlying_token\").str.contains(TOKEN)) \\\n",
    "    .filter(pl.col(\"date\") > START_DATE) \\\n",
    "    .unique(\"project\") \\\n",
    "    .pivot(index=\"date\", columns=\"project\", values=[\"apy\", \"tvlUsd\"]) \"\"\"\n",
    "\n",
    "apy_df = top_apy_per_protocol \\\n",
    "    .filter(pl.col(\"underlying_token\").str.contains(TOKEN)) \\\n",
    "    .with_columns(\n",
    "            pl.col(\"project\") + \"_\" + pl.col(\"chain\") +  pl.col(\"underlying_token\")\n",
    "    ) \\\n",
    "    .drop([\"underlying_token\", \"chain\"])\n",
    "\n",
    "unique_projects = apy_df \\\n",
    "    .filter(pl.col(\"date\") <= START_DATE) \\\n",
    "    .select(\"project\") \\\n",
    "    .unique()\n",
    "\n",
    "apy_df_token = apy_df.join(\n",
    "    unique_projects, \n",
    "    on=\"project\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "unique_token_projects = apy_df_token.pivot(\n",
    "    index=\"date\",\n",
    "    columns=\"project\",\n",
    "    values=[\"tvlUsd\", \"apy\"]\n",
    ")\n",
    "\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(unique_token_projects.head(n = 3))\n",
    "print(\"Number of rows in the dataset:\", len(unique_token_projects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset read from cache.\n",
      "Loading dataset tvl-per-project-tokens from cache.\n",
      "First few rows of the dataset:\n",
      "shape: (3, 20)\n",
      "┌────────────┬──────────┬──────────┬──────┬───┬───────────┬────────────┬────────────┬──────────────┐\n",
      "│ date       ┆ aave-v2  ┆ aave-v3  ┆ aura ┆ … ┆ sushiswap ┆ uniswap-v2 ┆ uniswap-v3 ┆ yearn-financ │\n",
      "│            ┆          ┆          ┆      ┆   ┆           ┆            ┆            ┆ e            │\n",
      "╞════════════╪══════════╪══════════╪══════╪═══╪═══════════╪════════════╪════════════╪══════════════╡\n",
      "│ 2022-06-19 ┆ 6.4884e8 ┆ 1.4889e8 ┆ null ┆ … ┆ 4.1608e7  ┆ null       ┆ 7.7758e8   ┆ null         │\n",
      "│ 2022-06-21 ┆ 7.2726e8 ┆ 1.6970e8 ┆ null ┆ … ┆ 4.7141e7  ┆ null       ┆ 8.0020e8   ┆ null         │\n",
      "│ 2022-06-22 ┆ 7.3875e8 ┆ 1.6967e8 ┆ null ┆ … ┆ 4.7820e7  ┆ null       ┆ 7.8998e8   ┆ null         │\n",
      "└────────────┴──────────┴──────────┴──────┴───┴───────────┴────────────┴────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "tvl_df = DatasetsLoader().load(\"tvl-per-project-tokens\") \\\n",
    "    .unique(subset=[\"date\", \"project\"]) \\\n",
    "    .filter(pl.col(\"date\") > START_DATE) \n",
    "\n",
    "tvl_per_projects_token = tvl_df[[TOKEN, \"project\", \"date\"]].pivot(\n",
    "    index=\"date\",\n",
    "    columns=\"project\",\n",
    "    values=TOKEN\n",
    ")\n",
    "\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(tvl_per_projects_token.head(n = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "shape: (3, 162)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ volumes_l ┆ price_dif ┆ price_dif ┆ price_dif ┆ … ┆ apy_proje ┆ apy_proje ┆ apy_proje ┆ apy_proj │\n",
      "│ ast_24h   ┆ f_1_days  ┆ f_3_days  ┆ f_7_days  ┆   ┆ ct_uniswa ┆ ct_uniswa ┆ ct_uniswa ┆ ect_year │\n",
      "│           ┆           ┆           ┆           ┆   ┆ p-v3_Arbi ┆ p-v3_Arbi ┆ p-v3_Ethe ┆ n-financ │\n",
      "│           ┆           ┆           ┆           ┆   ┆ trumW…    ┆ trumW…    ┆ reumW…    ┆ e_Ethere │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 1.024704  ┆ -2.197109 ┆ 0.11474   ┆ -0.843464 ┆ … ┆ -0.576543 ┆ -0.54936  ┆ -0.044265 ┆ -0.92143 │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 2        │\n",
      "│ 0.498189  ┆ 0.064754  ┆ -1.764524 ┆ 0.120361  ┆ … ┆ -0.678317 ┆ -0.580351 ┆ -0.044265 ┆ -0.94637 │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 2        │\n",
      "│ 0.246527  ┆ -1.042419 ┆ -1.890364 ┆ 0.298075  ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ -0.94850 │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 5        │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Join the datasets by the date column to create the final dataset\n",
    "final_dataset = price_dataset \\\n",
    "    .join(tvl_per_projects_token, on=\"date\", how=\"inner\") \\\n",
    "    .join(unique_token_projects, on=\"date\", how=\"inner\")\n",
    "\n",
    "# Drop unnecessary columns and rows with irrelevant data\n",
    "# - columns with token, market_cap , date and current price: not relevant for the model\n",
    "# - rows with year < 2022: historical data is not relevant\n",
    "final_dataset = final_dataset \\\n",
    "    .filter(pl.col(\"year\") >= 2022) \\\n",
    "    .drop([\"token\", \"market_cap\", \"date\", \"price\", \"month\"])\n",
    "final_dataset = final_dataset.slice(0, len(final_dataset) - 1)\n",
    "# Drop columns if there are lots of missing values\n",
    "THRESHOLD = 0.2\n",
    "max_nulls = THRESHOLD * final_dataset.shape[0]\n",
    "columns_to_keep = [\n",
    "        col_name for col_name in final_dataset.columns if final_dataset[col_name].null_count() <= max_nulls\n",
    "]\n",
    "final_dataset = final_dataset.select(columns_to_keep    )\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "features = final_dataset.drop(\"label\")\n",
    "labels = final_dataset[\"label\"]\n",
    "\n",
    "# Normalize the training dataset and fill missing values\n",
    "for col in features.columns:\n",
    "    mean_val = features[col].mean()\n",
    "    std_dev = features[col].std() if features[col].std() != 0 else 1\n",
    "    features = features.with_columns(((features[col].fill_null(mean_val) - mean_val) / std_dev).alias(col))\n",
    "\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(features.head(n = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "##### Splitting the dataset\n",
    "\n",
    "We need to convert the dataframes to torch tensors and split the dataset into training and testing sets. As usual, we choose a reasonable split ratio (e.g., 80% training and 20% testing) and shuffle the data before splitting it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to a PyTorch tensor\n",
    "features_tensor = torch.tensor(features.to_numpy(), dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "# Get a random permutation of the indices\n",
    "indices = torch.randperm(len(features_tensor))\n",
    "train_indices = indices[:int(0.75 * len(features_tensor))]\n",
    "test_indices = indices[int(0.75 * len(features_tensor)):]\n",
    "train_features, train_labels = features_tensor[train_indices], labels_tensor[train_indices]\n",
    "test_features, test_labels = features_tensor[test_indices], labels_tensor[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definition\n",
    "\n",
    "For the sake of simplicity, we illustrate the training process using a simple perceptron model no hidden layers and a single output neuron. We use the Sigmoid activation function to output the probability of the token price increasing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(len(features.columns), 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Model\n",
    "\n",
    "We then train the model on the Binary Cross-Entropy loss function and the Adam optimizer. For the hyperparameters, we use a learning rate of 0.01 and 500 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.00%\n"
     ]
    }
   ],
   "source": [
    "def train_and_test_model(model, train_features, train_labels, test_features, test_labels, criterion, optimizer):\n",
    "    model.train()\n",
    "    for _ in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_features)\n",
    "        loss = criterion(output, train_labels.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        output = model(test_features)\n",
    "        predicted = torch.tensor([1 if x > 0.5 else 0 for x in output])\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "acc = train_and_test_model(model, train_features, train_labels, test_features, test_labels, criterion, optimizer)\n",
    "print(f'Accuracy: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple Logistic Regression model obtains an accuracy of 0.70 on the test set. In the original example from GIZA, the authors trained a Multilayer Perceptron model with 2 hidden layers of decreasing input size (64 and 32). Using their feature extraction process, their MLP achieved an accuracy of around 0.65. In the final part of this article, we will show how the accuracy can be further improved by training more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmarking Proof Generation\n",
    "\n",
    "Once the model is trained, we can generate a proof of its inference using EZKL. We first convert the model to the ONNX format and set up the proof generation process as described in the previous sections. To simplify the process, let us write a few helper functions to convert the model to ONNX format and time the proof generation process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from typing import Tuple, Union\n",
    "import time\n",
    "import torch\n",
    "import sklearn as sk\n",
    "\n",
    "def to_onnx(model, input_sample, onnx_file):\n",
    "    # if the file already exists, delete it\n",
    "    if os.path.exists(onnx_file):\n",
    "        os.remove(onnx_file)\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        input_sample,\n",
    "        onnx_file,\n",
    "        input_names = ['input'],             # Input and output labels to appear in the ONNX graph \n",
    "        output_names = ['output'],\n",
    "        opset_version=10,\n",
    "        do_constant_folding=True,\n",
    "        export_params=True, \n",
    "        dynamic_axes={\n",
    "            'input' : {0 : 'batch_size'},    # Variable length axes\n",
    "            'output' : {0 : 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "\n",
    "def prove():\n",
    "    _= ezkl.prove(\n",
    "        WITNESS,\n",
    "        COMPILED_MODEL,\n",
    "        PK,\n",
    "        PROOF,\n",
    "        \"single\",\n",
    "    )\n",
    "\n",
    "def verify():\n",
    "    assert ezkl.verify(\n",
    "        PROOF,\n",
    "        SETTINGS,\n",
    "        VK,\n",
    "    ) == True\n",
    "\n",
    "import contextlib\n",
    "\n",
    "def bench_ezkl_single_round(\n",
    "    model: Union[torch.nn.Module, sk.base.BaseEstimator],\n",
    "    sample: torch.Tensor, \n",
    ") -> Tuple[float, float, float, int]:\n",
    "    \n",
    "    setup_time = -time.time()\n",
    "    with contextlib.redirect_stderr(None):\n",
    "        setup(\"perceptron.onnx\", model, sample)\n",
    "    setup_time += time.time()\n",
    "\n",
    "    logrows = json.load(open(SETTINGS, 'r'))[\"run_args\"][\"logrows\"]\n",
    "    \n",
    "    # Sleep for 1 second to make sure Rust has enough time to write the files\n",
    "    time.sleep(1) \n",
    "\n",
    "    prove_time = -time.time()\n",
    "    prove()\n",
    "    prove_time += time.time()\n",
    "\n",
    "    time.sleep(1) \n",
    "\n",
    "    verify_time = -time.time()\n",
    "    verify()\n",
    "    verify_time += time.time()\n",
    "\n",
    "    return setup_time, prove_time, verify_time, logrows\n",
    "\n",
    "def bench_ezkl(\n",
    "    model: Union[torch.nn.Module, sk.base.BaseEstimator],\n",
    "    test_features: torch.Tensor,\n",
    "    rounds: int = 1,\n",
    ") -> Tuple[float, float, float]:\n",
    "    \n",
    "    # Convert the model to ONNX and calibrate it\n",
    "    to_onnx(model, test_features[0].unsqueeze(0), \"perceptron.onnx\")  \n",
    "\n",
    "    setup_time, prove_time, verify_time, logrows = [], [], [], []\n",
    "    for _ in range(rounds):\n",
    "        # Reload the module to avoid any caching issues\n",
    "\n",
    "        from importlib import reload\n",
    "        import ezkl\n",
    "        reload(ezkl)\n",
    "\n",
    "        # randomly sample a feature from the test dataset\n",
    "        sample = test_features[torch.randint(0, len(test_features), (1,))]\n",
    "        s, p, v, l = bench_ezkl_single_round(model, sample)\n",
    "        setup_time.append(s), prove_time.append(p), verify_time.append(v), logrows.append(l)\n",
    "\n",
    "    # Calculate the average and standard deviation of the timings\n",
    "    avg_setup, avg_prove, avg_verify, avg_logrows = (\n",
    "        sum(setup_time) / rounds, \n",
    "        sum(prove_time) / rounds, \n",
    "        sum(verify_time) / rounds,\n",
    "        sum(logrows) / rounds\n",
    "    )\n",
    "\n",
    "    std_setup, std_prove, std_verify, std_logrows = (\n",
    "        (sum((s - avg_setup) ** 2 for s in setup_time) / rounds) ** 0.5,\n",
    "        (sum((p - avg_prove) ** 2 for p in prove_time) / rounds) ** 0.5,\n",
    "        (sum((v - avg_verify) ** 2 for v in verify_time) / rounds) ** 0.5,\n",
    "        (sum((l - avg_logrows) ** 2 for l in logrows) / rounds) ** 0.5\n",
    "    )\n",
    "\n",
    "    print(f\"Setup time: {str(avg_setup)[:5]} ± {str(std_setup/math.sqrt(rounds))[:5]} [s]\")\n",
    "    print(f\"Prover time: {str(avg_prove)[:5]} ± {str(std_prove/math.sqrt(rounds))[:5]} [s]\")\n",
    "    print(f\"Verifier time: {str(avg_verify)[:5]} ± {str(std_verify/math.sqrt(rounds))[:5]} [s]\")\n",
    "    print(f\"Logrows: {str(avg_logrows)[:5]} ± {str(std_logrows/math.sqrt(rounds))[:5]}\")\n",
    "    \n",
    "    return setup_time, prove_time, verify_time, logrows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now time the `setup`, `prove`, and `verify` functions by calling the `bench_ezkl` function, which allows us to obtain average times with error margins by specifying the number of `rounds`. Let's benchmark the proof generation process for the simple perceptron model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup time: 0.646 ± 0.0 [s]\n",
      "Prover time: 1.010 ± 0.0 [s]\n",
      "Verifier time: 0.014 ± 0.0 [s]\n",
      "Logrows: 12.0 ± 0.0\n"
     ]
    }
   ],
   "source": [
    "_ = bench_ezkl(\n",
    "    model,\n",
    "    test_features,\n",
    "    rounds=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy vs. Proving Costs\n",
    "\n",
    "For the main part of this article, we will compare the accuracy of the model with the cost of proving its inference. On the one hand, we increase the number of hidden layers and neurons of the perceptron model to show how a linear increase yields a linear increase in proof cost but a diminishing return in accuracy. On the other hand, we show how different architectures (e.g., Decision Trees, Random Forests, and SVMs) can obtain similar accuracies with varying proof costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing Model Complexity\n",
    "\n",
    "Let's start by increasing the complexity of the perceptron model. We evaluate perceptrons with one, two and three hidden layers for which we vary the number of neurons per layer as follows. We define the possible number of neurons per layer to be one of the following: [4, 8, 16, 32, 64, 128]. In addition, for any two consecutive layers, the outermost layer must have striclty less neurons than the inner one. We then train the model for each configuration and obtain the accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# Function to create a MLP model with the specified information\n",
    "def create_mlp_model(layer_info: List[Tuple[int, int]]) -> nn.Module:\n",
    "    layers = (\n",
    "        nn.Linear(in_size, out_size)\n",
    "        for in_size, out_size in layer_info\n",
    "    )\n",
    "    return nn.Sequential(*layers, nn.Sigmoid())\n",
    "\n",
    "\n",
    "# Function to train and return the model accuracy\n",
    "def train_and_return_model(model: nn.Module) -> Tuple[nn.Module, float]:\n",
    "    # Get a random permutation of the indices\n",
    "    indices = torch.randperm(len(features_tensor))\n",
    "    train_indices = indices[:int(0.75 * len(features_tensor))]\n",
    "    test_indices = indices[int(0.75 * len(features_tensor)):]\n",
    "    train_features, train_labels = features_tensor[train_indices], labels_tensor[train_indices]\n",
    "    test_features, test_labels = features_tensor[test_indices], labels_tensor[test_indices]\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "    acc = train_and_test_model(model, train_features, train_labels, test_features, test_labels, criterion, optimizer)\n",
    "    return model, acc\n",
    "\n",
    "def get_num_params(name: str) -> int:\n",
    "    numbers = [len(features.columns)] + [\n",
    "        int(s) for s in name.split('_')[3:] if s.isdigit()] + [1]\n",
    "    weights = sum([s1 * s2 for s1, s2 in zip(numbers, numbers[1:])])\n",
    "    biases = sum(numbers[1:])\n",
    "    return weights + biases\n",
    "\n",
    "# Given the number of layers, return all possible decreasing configurations\n",
    "# Where the number of neurons is in [4, 8, 16, 32, 64]\n",
    "def get_all_configurations(n_layers: int, in_features: int = len(features.columns)) -> List[List[int]]:\n",
    "    if n_layers == 0:\n",
    "        return [[(in_features, 1)]]\n",
    "\n",
    "    in_sizes = [128, 64, 32, 16, 8, 4]\n",
    "    combinations = list(itertools.combinations_with_replacement(in_sizes, n_layers))\n",
    "    increasing_combinations = [\n",
    "        c for c in combinations\n",
    "        if all(c[i] > c[i + 1] for i in range(len(c) - 1))\n",
    "    ]\n",
    "\n",
    "    sizes =[ \n",
    "        [(in_features, c[0])] + [\n",
    "            (c1, c2) for c1, c2 in zip(c, c[1:])\n",
    "        ] + [(c[-1], 1)]\n",
    "        for c in increasing_combinations\n",
    "    ]\n",
    "                                \n",
    "    return sizes\n",
    "\n",
    "# Dictionary to store the accuracy of each model\n",
    "acc = {}\n",
    "ROUNDS = 20\n",
    "\n",
    "for _ in range(ROUNDS):\n",
    "    for layers in range(0, 4):\n",
    "        for layer_info in get_all_configurations(layers):\n",
    "            model, accuracy = train_and_return_model(\n",
    "                create_mlp_model(layer_info)\n",
    "            )\n",
    "            tag = f\"MLP_{layers}_layers_{'_'.join(str(x[0]) for x in layer_info[1:])}\"\n",
    "            acc[tag] = acc.get(tag, []) + [accuracy]\n",
    "\n",
    "# Print the average accuracy for each model\n",
    "sorted_acc = sorted(acc.items(), key=lambda x: get_num_params(x[0]))\n",
    "for name, accuracies in sorted_acc:\n",
    "    print(f\"{name}: {str(sum(accuracies) / len(accuracies))[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the accuracy of the models correlates with the number of neurons per layer. However, at some point, the increase in accuracy becomes marginal or even stagnates. This is due to overfitting, as the model becomes too complex and starts to memorize the training data instead of generalizing well to unseen data. We will now observe how the proof costs increase with the number of neurons per layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_0_layers_ (163 params)\n",
      "\n",
      "Setup time: 1.083 ± 0.103 [s]\n",
      "Prover time: 1.347 ± 0.137 [s]\n",
      "Verifier time: 0.015 ± 0.000 [s]\n",
      "Logrows: 12.58 ± 0.098\n",
      "\n",
      "\n",
      "MLP_1_layers_128 (20993 params)\n",
      "\n",
      "Setup time: 6.567 ± 0.454 [s]\n",
      "Prover time: 6.862 ± 0.643 [s]\n",
      "Verifier time: 0.019 ± 0.000 [s]\n",
      "Logrows: 14.72 ± 0.109\n",
      "\n",
      "\n",
      "MLP_1_layers_64 (10497 params)\n",
      "\n",
      "Setup time: 4.447 ± 0.506 [s]\n",
      "Prover time: 5.019 ± 0.692 [s]\n",
      "Verifier time: 0.018 ± 0.000 [s]\n",
      "Logrows: 14.12 ± 0.161\n",
      "\n",
      "\n",
      "MLP_1_layers_32 (5249 params)\n",
      "\n",
      "Setup time: 3.736 ± 0.457 [s]\n",
      "Prover time: 4.460 ± 0.629 [s]\n",
      "Verifier time: 0.017 ± 0.000 [s]\n",
      "Logrows: 13.8 ± 0.203\n",
      "\n",
      "\n",
      "MLP_1_layers_16 (2625 params)\n",
      "\n",
      "Setup time: 2.596 ± 0.343 [s]\n",
      "Prover time: 3.054 ± 0.458 [s]\n",
      "Verifier time: 0.017 ± 0.000 [s]\n",
      "Logrows: 13.38 ± 0.174\n",
      "\n",
      "\n",
      "MLP_1_layers_8 (1313 params)\n",
      "\n",
      "Setup time: 1.881 ± 0.173 [s]\n",
      "Prover time: 2.271 ± 0.237 [s]\n",
      "Verifier time: 0.017 ± 0.000 [s]\n",
      "Logrows: 13.22 ± 0.147\n",
      "\n",
      "\n",
      "MLP_1_layers_4 (657 params)\n",
      "\n",
      "Setup time: 1.347 ± 0.115 [s]\n",
      "Prover time: 1.593 ± 0.160 [s]\n",
      "Verifier time: 0.015 ± 0.000 [s]\n",
      "Logrows: 12.84 ± 0.127\n",
      "\n",
      "\n",
      "MLP_2_layers_128_64 (29185 params)\n",
      "\n",
      "Setup time: 12.15 ± 1.550 [s]\n",
      "Prover time: 14.07 ± 2.117 [s]\n",
      "Verifier time: 0.025 ± 0.001 [s]\n",
      "Logrows: 15.66 ± 0.186\n",
      "\n",
      "\n",
      "MLP_2_layers_128_32 (25025 params)\n",
      "\n",
      "Setup time: 11.67 ± 1.511 [s]\n",
      "Prover time: 13.70 ± 2.043 [s]\n",
      "Verifier time: 0.023 ± 0.001 [s]\n",
      "Logrows: 15.72 ± 0.174\n",
      "\n",
      "\n",
      "MLP_2_layers_128_16 (22945 params)\n",
      "\n",
      "Setup time: 8.819 ± 1.033 [s]\n",
      "Prover time: 10.15 ± 1.432 [s]\n",
      "Verifier time: 0.021 ± 0.001 [s]\n",
      "Logrows: 15.22 ± 0.181\n",
      "\n",
      "\n",
      "MLP_2_layers_128_8 (21905 params)\n",
      "\n",
      "Setup time: 7.176 ± 0.626 [s]\n",
      "Prover time: 7.855 ± 0.853 [s]\n",
      "Verifier time: 0.019 ± 0.000 [s]\n",
      "Logrows: 15.1 ± 0.136\n",
      "\n",
      "\n",
      "MLP_2_layers_128_4 (21385 params)\n",
      "\n",
      "Setup time: 7.028 ± 0.806 [s]\n",
      "Prover time: 7.637 ± 1.107 [s]\n",
      "Verifier time: 0.020 ± 0.000 [s]\n",
      "Logrows: 14.96 ± 0.141\n",
      "\n",
      "\n",
      "MLP_2_layers_64_32 (12545 params)\n",
      "\n",
      "Setup time: 7.848 ± 0.983 [s]\n",
      "Prover time: 9.396 ± 1.342 [s]\n",
      "Verifier time: 0.020 ± 0.001 [s]\n",
      "Logrows: 15.14 ± 0.187\n",
      "\n",
      "\n",
      "MLP_2_layers_64_16 (11489 params)\n",
      "\n",
      "Setup time: 8.447 ± 1.315 [s]\n",
      "Prover time: 10.35 ± 1.802 [s]\n",
      "Verifier time: 0.022 ± 0.001 [s]\n",
      "Logrows: 15.22 ± 0.194\n",
      "\n",
      "\n",
      "MLP_2_layers_64_8 (10961 params)\n",
      "\n",
      "Setup time: 8.747 ± 1.708 [s]\n",
      "Prover time: 10.85 ± 2.357 [s]\n",
      "Verifier time: 0.021 ± 0.001 [s]\n",
      "Logrows: 14.96 ± 0.229\n",
      "\n",
      "\n",
      "MLP_2_layers_64_4 (10697 params)\n",
      "\n",
      "Setup time: 7.472 ± 0.931 [s]\n",
      "Prover time: 9.272 ± 1.285 [s]\n",
      "Verifier time: 0.021 ± 0.001 [s]\n",
      "Logrows: 15.18 ± 0.182\n",
      "\n",
      "\n",
      "MLP_2_layers_32_16 (5761 params)\n",
      "\n",
      "Setup time: 7.440 ± 0.994 [s]\n",
      "Prover time: 9.506 ± 1.383 [s]\n",
      "Verifier time: 0.021 ± 0.001 [s]\n",
      "Logrows: 15.14 ± 0.195\n",
      "\n",
      "\n",
      "MLP_2_layers_32_8 (5489 params)\n",
      "\n",
      "Setup time: 5.245 ± 0.607 [s]\n",
      "Prover time: 6.522 ± 0.822 [s]\n",
      "Verifier time: 0.019 ± 0.000 [s]\n",
      "Logrows: 14.64 ± 0.191\n",
      "\n",
      "\n",
      "MLP_2_layers_32_4 (5353 params)\n",
      "\n",
      "Setup time: 4.909 ± 0.452 [s]\n",
      "Prover time: 6.004 ± 0.609 [s]\n",
      "Verifier time: 0.018 ± 0.000 [s]\n",
      "Logrows: 14.6 ± 0.187\n",
      "\n",
      "\n",
      "MLP_2_layers_16_8 (2753 params)\n",
      "\n",
      "Setup time: 4.704 ± 0.531 [s]\n",
      "Prover time: 5.970 ± 0.725 [s]\n",
      "Verifier time: 0.018 ± 0.000 [s]\n",
      "Logrows: 14.54 ± 0.192\n",
      "\n",
      "\n",
      "MLP_2_layers_16_4 (2681 params)\n",
      "\n",
      "Setup time: 4.222 ± 0.466 [s]\n",
      "Prover time: 5.347 ± 0.656 [s]\n",
      "Verifier time: 0.018 ± 0.000 [s]\n",
      "Logrows: 14.36 ± 0.195\n",
      "\n",
      "\n",
      "MLP_2_layers_8_4 (1345 params)\n",
      "\n",
      "Setup time: 2.635 ± 0.283 [s]\n",
      "Prover time: 3.280 ± 0.391 [s]\n",
      "Verifier time: 0.015 ± 0.000 [s]\n",
      "Logrows: 13.7 ± 0.181\n",
      "\n",
      "\n",
      "MLP_3_layers_128_64_32 (31233 params)\n",
      "\n",
      "Setup time: 12.02 ± 1.798 [s]\n",
      "Prover time: 13.75 ± 2.515 [s]\n",
      "Verifier time: 0.024 ± 0.001 [s]\n",
      "Logrows: 15.42 ± 0.211\n",
      "\n",
      "\n",
      "MLP_3_layers_128_64_16 (30177 params)\n",
      "\n",
      "Setup time: 8.130 ± 0.752 [s]\n",
      "Prover time: 8.395 ± 1.038 [s]\n",
      "Verifier time: 0.019 ± 0.000 [s]\n",
      "Logrows: 15.08 ± 0.154\n",
      "\n",
      "\n",
      "MLP_3_layers_128_64_8 (29649 params)\n",
      "\n",
      "Setup time: 10.79 ± 1.465 [s]\n",
      "Prover time: 12.15 ± 2.029 [s]\n",
      "Verifier time: 0.022 ± 0.001 [s]\n",
      "Logrows: 15.44 ± 0.183\n",
      "\n",
      "\n",
      "MLP_3_layers_128_64_4 (29385 params)\n",
      "\n",
      "Setup time: 9.798 ± 1.001 [s]\n",
      "Prover time: 10.73 ± 1.377 [s]\n",
      "Verifier time: 0.022 ± 0.001 [s]\n",
      "Logrows: 15.38 ± 0.176\n",
      "\n",
      "\n",
      "MLP_3_layers_128_32_16 (25537 params)\n",
      "\n",
      "Setup time: 13.97 ± 3.579 [s]\n",
      "Prover time: 16.12 ± 4.382 [s]\n",
      "Verifier time: 0.025 ± 0.003 [s]\n",
      "Logrows: 15.56 ± 0.202\n",
      "\n",
      "\n",
      "MLP_3_layers_128_32_8 (25265 params)\n",
      "\n",
      "Setup time: 12.81 ± 1.491 [s]\n",
      "Prover time: 15.27 ± 2.070 [s]\n",
      "Verifier time: 0.025 ± 0.001 [s]\n",
      "Logrows: 15.88 ± 0.188\n",
      "\n",
      "\n",
      "MLP_3_layers_128_32_4 (25129 params)\n",
      "\n",
      "Setup time: 10.47 ± 0.868 [s]\n",
      "Prover time: 12.14 ± 1.196 [s]\n",
      "Verifier time: 0.022 ± 0.000 [s]\n",
      "Logrows: 15.68 ± 0.170\n",
      "\n",
      "\n",
      "MLP_3_layers_128_16_8 (23073 params)\n",
      "\n",
      "Setup time: 10.34 ± 1.295 [s]\n",
      "Prover time: 12.21 ± 1.814 [s]\n",
      "Verifier time: 0.023 ± 0.001 [s]\n",
      "Logrows: 15.6 ± 0.167\n",
      "\n",
      "\n",
      "MLP_3_layers_128_16_4 (23001 params)\n",
      "\n",
      "Setup time: 11.33 ± 1.528 [s]\n",
      "Prover time: 13.63 ± 2.139 [s]\n",
      "Verifier time: 0.023 ± 0.001 [s]\n",
      "Logrows: 15.54 ± 0.206\n",
      "\n",
      "\n",
      "MLP_3_layers_128_8_4 (21937 params)\n",
      "\n",
      "Setup time: 9.525 ± 1.004 [s]\n",
      "Prover time: 11.12 ± 1.388 [s]\n",
      "Verifier time: 0.021 ± 0.001 [s]\n",
      "Logrows: 15.46 ± 0.177\n",
      "\n",
      "\n",
      "MLP_3_layers_64_32_16 (13057 params)\n",
      "\n",
      "Setup time: 10.87 ± 1.291 [s]\n",
      "Prover time: 13.51 ± 1.784 [s]\n",
      "Verifier time: 0.022 ± 0.001 [s]\n",
      "Logrows: 15.82 ± 0.178\n",
      "\n",
      "\n",
      "MLP_3_layers_64_32_8 (12785 params)\n",
      "\n",
      "Setup time: 8.922 ± 1.164 [s]\n",
      "Prover time: 10.94 ± 1.590 [s]\n",
      "Verifier time: 0.020 ± 0.001 [s]\n",
      "Logrows: 15.28 ± 0.207\n",
      "\n",
      "\n",
      "MLP_3_layers_64_32_4 (12649 params)\n",
      "\n",
      "Setup time: 8.119 ± 0.906 [s]\n",
      "Prover time: 9.786 ± 1.239 [s]\n",
      "Verifier time: 0.020 ± 0.001 [s]\n",
      "Logrows: 15.22 ± 0.198\n",
      "\n",
      "\n",
      "MLP_3_layers_64_16_8 (11617 params)\n",
      "\n",
      "Setup time: 10.27 ± 1.399 [s]\n",
      "Prover time: 12.80 ± 1.890 [s]\n",
      "Verifier time: 0.022 ± 0.001 [s]\n",
      "Logrows: 15.56 ± 0.208\n",
      "\n",
      "\n",
      "MLP_3_layers_64_16_4 (11545 params)\n",
      "\n",
      "Setup time: 11.64 ± 1.709 [s]\n",
      "Prover time: 14.81 ± 2.292 [s]\n",
      "Verifier time: 0.023 ± 0.002 [s]\n",
      "Logrows: 15.66 ± 0.230\n",
      "\n",
      "\n",
      "MLP_3_layers_64_8_4 (10993 params)\n",
      "\n",
      "Setup time: 9.178 ± 0.902 [s]\n",
      "Prover time: 11.49 ± 1.252 [s]\n",
      "Verifier time: 0.021 ± 0.001 [s]\n",
      "Logrows: 15.42 ± 0.221\n",
      "\n",
      "\n",
      "MLP_3_layers_32_16_8 (5889 params)\n",
      "\n",
      "Setup time: 8.447 ± 0.938 [s]\n",
      "Prover time: 10.72 ± 1.304 [s]\n",
      "Verifier time: 0.021 ± 0.001 [s]\n",
      "Logrows: 15.3 ± 0.223\n",
      "\n",
      "\n",
      "MLP_3_layers_32_16_4 (5817 params)\n",
      "\n",
      "Setup time: 6.303 ± 0.634 [s]\n",
      "Prover time: 7.798 ± 0.872 [s]\n",
      "Verifier time: 0.018 ± 0.000 [s]\n",
      "Logrows: 14.86 ± 0.220\n",
      "\n",
      "\n",
      "MLP_3_layers_32_8_4 (5521 params)\n",
      "\n",
      "Setup time: 7.001 ± 0.780 [s]\n",
      "Prover time: 8.865 ± 1.074 [s]\n",
      "Verifier time: 0.019 ± 0.001 [s]\n",
      "Logrows: 15.08 ± 0.209\n",
      "\n",
      "\n",
      "MLP_3_layers_16_8_4 (2785 params)\n",
      "\n",
      "Setup time: 4.872 ± 0.532 [s]\n",
      "Prover time: 6.113 ± 0.745 [s]\n",
      "Verifier time: 0.018 ± 0.000 [s]\n",
      "Logrows: 14.5 ± 0.212\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def bench_configuration(layer_info):\n",
    "    \n",
    "    layers = len(layer_info) - 1\n",
    "    tag = f\"MLP_{layers}_layers_{'_'.join(str(x[0]) for x in layer_info[1:])}\"\n",
    "    print(f\"{tag} ({get_num_params(tag)} params)\\n\")\n",
    "    \n",
    "    bench_ezkl(\n",
    "        train_and_return_model(create_mlp_model(layer_info))[0],\n",
    "        test_features,\n",
    "        rounds=50,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "for layers in range(0, 4):\n",
    "    for layer_info in get_all_configurations(layers):\n",
    "        bench_configuration(layer_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
